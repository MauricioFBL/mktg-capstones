# Marketing Analytics Pipeline

## ğŸ“Œ Description
This repository contains an end-to-end data analytics pipeline for digital marketing campaigns, leveraging AWS and Airflow (MWAA) for orchestration. The project enables data integration, storage, transformation, and visualization from various advertising platforms such as Meta, Google Ads, DV360, Snapchat, and TikTok.

## ğŸ“‚ Repository Structure
```
marketing-analytics-pipeline/
â”‚â”€â”€ dags/                     # Airflow (MWAA) DAGs for orchestration
â”‚â”€â”€ data/                     # Sample or test data
â”‚â”€â”€ scripts/                   # Data generation and ETL scripts
â”‚â”€â”€ config/                    # Configurations and credentials (DO NOT include real credentials)
â”‚â”€â”€ infrastructure/            # Infrastructure as Code (IaC)
â”‚â”€â”€ notebooks/                 # Jupyter Notebooks for exploratory analysis
â”‚â”€â”€ sql/                       # SQL queries for analysis
â”‚â”€â”€ reports/                   # Generated reports and dashboards
â”‚â”€â”€ visualization/             # Visualization scripts with QuickSight or Power BI
â”‚â”€â”€ docs/                      # Project documentation
â”‚â”€â”€ tests/                     # Unit and integration tests
â”œâ”€â”€ jobs/
â”‚   â”œâ”€â”€ social-media-mktg/
â”‚   â”‚   â””â”€â”€ social-media-big-tbl.py  # CÃ³digo del Glue Job
â”‚   â””â”€â”€ ...   
â”‚â”€â”€ build/                     # lambda functions zip packahes
â”‚â”€â”€ functions/                 # Lambda functions
â”‚       â””â”€â”€ function/
â”‚           â””â”€â”€ lambda_function.py
â”œâ”€â”€ infra/
â”‚   â””â”€â”€ terraform/
â”‚       â”œâ”€â”€ main.tf                  # Entrada general (proveedores, backend)
â”‚       â”œâ”€â”€ variables.tf             # Variables globales
â”‚       â”œâ”€â”€ terraform.tfvars         # Valores especÃ­ficos del entorno
â”‚       â”œâ”€â”€ outputs.tf               # Valores de salida Ãºtiles
â”‚       â”œâ”€â”€ backend.tf               # (opcional) configuraciÃ³n del backend remoto
â”‚       â”œâ”€â”€ provider.tf              # (opcional) definiciÃ³n de proveedor AWS
â”‚       â”œâ”€â”€ glue_jobs.tf             # DeclaraciÃ³n de todos los Glue Jobs
â”‚       â”œâ”€â”€ lambdas.tf               # DeclaraciÃ³n de funciones Lambda
â”‚       â”œâ”€â”€ mwaa.tf                  # DeclaraciÃ³n de entorno MWAA (mÃ¡s adelante)
â”‚       â”œâ”€â”€ iam.tf                   # Roles y polÃ­ticas IAM
â”‚       â”œâ”€â”€ s3_objects.tf            # Carga de scripts Glue/Lambda a S3
â”‚       â””â”€â”€ .terraform/              # Plugins (IGNORAR en git)
â”‚       â””â”€â”€ .terraform.lock.hcl      # Lock de proveedores (âœ… versionar)
â”‚
â”‚â”€â”€ config/      
â”‚â”€â”€ .gitignore                 # Files to ignore in Git
â”‚â”€â”€ requirements.txt           # Python dependencies
â”‚â”€â”€ Dockerfile                 # Docker setup
â”‚â”€â”€ setup.py                   # Custom package installation
```

## ğŸš€ Technologies Used
- **AWS Lambda, S3, Glue, Athena** for data storage and processing.
- **Airflow (MWAA)** for workflow orchestration.
- **Redshift, Snowflake** for structured data storage.
- **Power BI, QuickSight** for visualization and data analysis.
- **APIs from Meta, Google Ads, DV360, Snapchat, TikTok** for data ingestion.
- **Python, SQL** for data manipulation and transformation.

## ğŸ“Š Workflow
1. **Data Ingestion**: Fetching campaign data via APIs.
2. **Storage**: Saving data in S3 and analytical databases.
3. **Transformation**: Cleaning and structuring using Glue/Athena.
4. **Loading**: Inserting data into Redshift/Snowflake for analysis.
5. **Visualization**: Creating dashboards in Power BI/QuickSight.

## ğŸ›  Installation & Setup
### ğŸ“Œ Prerequisites
- Python 3.8+
- AWS CLI configured
- Docker (optional, for local development)
- Airflow (if running locally instead of MWAA)

### ğŸ“¥ Installation
```bash
# Clone the repository
git clone https://github.com/your_user/marketing-analytics-pipeline.git
cd marketing-analytics-pipeline

# Install dependencies
pip install -r requirements.txt
```

### ğŸš€ Running Locally
```bash
# Run a test DAG in Airflow
python scripts/generate_meta_data.py
```

## ğŸ¤ Contributions
Contributions are welcome! To propose changes, create a *pull request* with a detailed description.

## ğŸ“œ License
This project is licensed under MIT. See [LICENSE](LICENSE) for more details.

---
ğŸš€ Ready to turn data into strategic decisions! ğŸš€

```bash
# install docker
docker ps -al
docker build .
docker image ls 
sh init_docker.sh
```
